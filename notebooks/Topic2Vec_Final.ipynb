{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb902889-dad8-442b-a12b-2ebcb454060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from top2vec import Top2Vec\n",
    "\n",
    "# parameters\n",
    "DATA_PATH = Path(\"C:\\\\Users\\\\linna\\\\OneDrive\\\\Documents\\\\Python_Dev\\\\topic-modeling\\\\data\\\\public_comments.json\")\n",
    "TEXT_COL = \"comment_text\"\n",
    "DOC_ID_COL = \"comment_id\"\n",
    "DOCKET_TO_USE = \"TTB-2025-0003\"   # change as needed (or set to None to use full df)\n",
    "MODEL_SAVE_DIR = Path(\"top2vec_model_classic\")\n",
    "TOPIC_SUMMARY_CSV = Path(\"top2vec_topic_summary.csv\")\n",
    "OUTPUT_DF_CSV = Path(\"comments_with_top2vec.csv\")\n",
    "\n",
    "# top2vec training options\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "SPEED = \"learn\"        # 'fast-learn', 'learn', 'deep-learn' — choose based on time/quality tradeoff\n",
    "WORKERS = os.cpu_count() or 1\n",
    "\n",
    "# output params\n",
    "TOP_WORDS_PER_TOPIC = 10\n",
    "SAMPLE_DOCS_PER_TOPIC = 5\n",
    "TOP_N_FOR_LABEL = 5    # how many top words to use to create a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3480b7a-ebbf-4a2f-86b8-bd69b3e57e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top2vec_model_classic\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f726d2f-c276-47e8-a971-6c849aa09c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_FILE = Path(r\"C:\\Users\\linna\\Documents\\top2vec_model_classic.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2c54ad-2a97-42d1-8912-ab1b2bd98078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate notebook to functions\n",
    "def load_data(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_json(path, orient=\"records\", lines=False)\n",
    "    if TEXT_COL not in df.columns:\n",
    "        raise ValueError(f\"{TEXT_COL} not found in dataframe columns: {df.columns.tolist()}\")\n",
    "    df = df.dropna(subset=[TEXT_COL]).reset_index(drop=True)\n",
    "    print(f\"Loaded {len(df)} comments from {path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_by_docket(df: pd.DataFrame, docket: str | None) -> pd.DataFrame:\n",
    "    if docket is None:\n",
    "        return df\n",
    "    if \"docket_id\" not in df.columns:\n",
    "        raise ValueError(\"docket_id column not in dataframe\")\n",
    "    df_sub = df[df[\"docket_id\"] == docket].reset_index(drop=True)\n",
    "    print(f\"Filtered to docket '{docket}': {len(df_sub)} comments\")\n",
    "    return df_sub\n",
    "\n",
    "\n",
    "def train_top2vec(\n",
    "    documents: List[str],\n",
    "    document_ids: List[str],\n",
    "    embedding_model: str,\n",
    "    speed: str,\n",
    "    workers: int\n",
    ") -> Top2Vec:\n",
    "    print(\"Training Top2Vec:\")\n",
    "    print(f\"  embedding_model={embedding_model}, speed={speed}, workers={workers}\")\n",
    "    model = Top2Vec(\n",
    "        documents=documents,\n",
    "        document_ids=document_ids,\n",
    "        embedding_model=embedding_model,\n",
    "        speed=speed,\n",
    "        workers=workers\n",
    "    )\n",
    "    print(\"Training complete.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def map_dominant_and_topN(model: Top2Vec, df: pd.DataFrame, doc_id_col: str, text_col: str, topN: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds columns:\n",
    "      - top2vec_dominant_topic (int, -1 if missing)\n",
    "      - top2vec_top_topics (list of ints, length topN)\n",
    "    \"\"\"\n",
    "    doc_ids = df[doc_id_col].astype(str).tolist()\n",
    "    # dominant topic\n",
    "    try:\n",
    "        dominant_arr = model.get_documents_topics(doc_ids, num_topics=1)  # shape (n_docs, 1)\n",
    "        df[\"top2vec_dominant_topic\"] = dominant_arr[:, 0].astype(int)\n",
    "    except Exception:\n",
    "        # fallback to iterative approach if API/version mismatch\n",
    "        print(\"get_documents_topics failed; falling back to search_documents_by_topic iterative mapping.\")\n",
    "        docid_to_topic = {}\n",
    "        topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "        for size, tnum in zip(topic_sizes, topic_nums):\n",
    "            docs, doc_scores, doc_ids_for_topic = model.search_documents_by_topic(topic_num=tnum, num_docs=int(size))\n",
    "            for did in doc_ids_for_topic:\n",
    "                if did not in docid_to_topic:\n",
    "                    docid_to_topic[did] = tnum\n",
    "        df[\"top2vec_dominant_topic\"] = df[doc_id_col].astype(str).map(docid_to_topic).fillna(-1).astype(int)\n",
    "\n",
    "    # top-N topics per doc\n",
    "    try:\n",
    "        topN_arr = model.get_documents_topics(doc_ids, num_topics=topN)  # shape (n_docs, topN)\n",
    "        df[\"top2vec_top_topics\"] = list(topN_arr.tolist())\n",
    "        for i in range(topN):\n",
    "            df[f\"top2vec_topic_rank_{i+1}\"] = topN_arr[:, i].astype(int)\n",
    "    except Exception:\n",
    "        print(\"get_documents_topics (topN) not available; filling top2vec_top_topics with dominant only.\")\n",
    "        df[\"top2vec_top_topics\"] = df[\"top2vec_dominant_topic\"].apply(lambda x: [int(x)])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_topic_label_map(model: Top2Vec, top_k_words: int = 5) -> Dict[int, str]:\n",
    "    n_topics = model.get_num_topics()\n",
    "    topic_words, word_scores, topic_nums = model.get_topics(n_topics)\n",
    "    label_map = {}\n",
    "    for tnum, words in zip(topic_nums, topic_words):\n",
    "        words_sel = words[:top_k_words]\n",
    "        label_map[int(tnum)] = \", \".join(words_sel)\n",
    "    return label_map\n",
    "\n",
    "\n",
    "def build_topic_summary_df(model: Top2Vec, df: pd.DataFrame, text_col: str, top_words: int = 10, sample_docs: int = 5) -> pd.DataFrame:\n",
    "    topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "    # to gather words: request all topics\n",
    "    n_topics = len(topic_nums)\n",
    "    topic_words_all, _, topic_numbers_all = model.get_topics(n_topics)\n",
    "\n",
    "    rows = []\n",
    "    for i, tnum in enumerate(topic_nums):\n",
    "        size = int(topic_sizes[i])\n",
    "        # find words corresponding to tnum (topic_numbers_all may be same order as topic_nums)\n",
    "        idx = list(topic_numbers_all).index(tnum) if tnum in topic_numbers_all else i\n",
    "        words = topic_words_all[idx][:top_words]\n",
    "        # sample docs\n",
    "        num_to_get = min(sample_docs, size if size > 0 else 1)\n",
    "        docs, doc_scores, doc_ids = model.search_documents_by_topic(topic_num=tnum, num_docs=num_to_get)\n",
    "        sample_texts = []\n",
    "        for did, doc_text in zip(doc_ids, docs):\n",
    "            # try to map back to original df text if present\n",
    "            mask = df[\"comment_id\"].astype(str) == str(did)\n",
    "            if mask.any():\n",
    "                sample_texts.append(df.loc[mask, text_col].iloc[0])\n",
    "            else:\n",
    "                sample_texts.append(doc_text)\n",
    "        rows.append({\n",
    "            \"topic_num\": int(tnum),\n",
    "            \"size\": size,\n",
    "            \"top_words\": \", \".join(words),\n",
    "            \"sample_comments\": \" ||| \".join([s[:400].replace(\"\\n\", \" \") for s in sample_texts])\n",
    "        })\n",
    "    summary_df = pd.DataFrame(rows).sort_values(\"size\", ascending=False).reset_index(drop=True)\n",
    "    return summary_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3472e25a-d792-4779-9a51-8fd4b2ccf332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 15:44:47,913 - top2vec - INFO - Pre-processing documents for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12437 comments from C:\\Users\\linna\\OneDrive\\Documents\\Python_Dev\\topic-modeling\\data\\public_comments.json\n",
      "Filtered to docket 'TTB-2025-0003': 189 comments\n",
      "Docs in df: 189\n",
      "Training Top2Vec:\n",
      "  embedding_model=all-MiniLM-L6-v2, speed=learn, workers=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linna\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2025-08-27 15:44:48,229 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n",
      "2025-08-27 15:44:49,541 - top2vec - INFO - Creating joint document/word embedding\n",
      "2025-08-27 15:45:02,616 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2025-08-27 15:45:42,179 - top2vec - INFO - Finding dense areas of documents\n",
      "C:\\Users\\linna\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\linna\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-08-27 15:45:42,205 - top2vec - INFO - Finding topics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "Number of topics discovered: 2\n",
      "Top 10 topic sizes (docs per topic):\n",
      "  Topic 0: 118 documents\n",
      "  Topic 1: 71 documents\n",
      "get_documents_topics failed; falling back to search_documents_by_topic iterative mapping.\n",
      "get_documents_topics (topN) not available; filling top2vec_top_topics with dominant only.\n",
      "Topic summary saved to top2vec_topic_summary.csv\n",
      "Comments with topic columns saved to comments_with_top2vec.csv\n",
      "Model saved to: C:\\Users\\linna\\Documents\\top2vec_model_classic.pkl\n",
      "topic_summary (top rows):\n",
      " topic_num  size                                                                                           top_words                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      sample_comments\n",
      "         0   118 allergens, allergies, label, labeling, labels, alcohol, allergen, beverages, consumers, ingredients Public Comment on Notice No. 238 &ndash; Major Food Allergen Labeling for Alcohol Beverages<br/><br/>I am writing in support of TTB&rsquo;s proposed rule to require mandatory labeling of major food allergens on alcohol beverages. As someone who works at Walgreens, where we operate a liquor store, I have seen firsthand how alcohol products currently lack clear allergen labeling. While I have not ye ||| ​The Alcohol and Tobacco Tax and Trade Bureau proposes requiring alcohol beverage labels to disclose major food allergens used in production, aiming to protect consumers with allergies and enhance transparency. This measure affects stakeholders involved in distribution and production of particular alcohol beverages to identify common allergens on product labels. Such a change would greatly impact  ||| As a parent and public health professional, I am writing in strong support of the proposed rule to require allergen labeling on alcoholic beverages. I know firsthand how critical it is to have clear, accessible information about what&rsquo;s in our food and drinks&mdash;for safety, for health, and for peace of mind.<br/><br/>More than 1 in 10 U.S. adults have food allergies, and the consequences o ||| I have been a volunteer in the field of substance abuse prevention for over 25 years. I have a Masters degree in Dietetics. I think it is extremely important to label all foods and beverages to prevent allergic reactions and drug interactions.<br/>Roughly 11% of U.S. adults have food allergies.Many alcoholic beverages contain major allergens, such as wheat in many beers, milk and nuts in liqueurs, ||| I would like to fully support TTB&#39;s proposal to require a labeling disclosure of all major food allergens used in the production of alcohol beverages subject to TTB&#39;s regulatory authority under the Federal Alcohol Administration Act. Under the proposed regulations, unless an exception applies, labels must declare milk, eggs, fish, Crustacean shellfish, tree nuts, wheat, peanuts, soybeans, \n",
      "         1    71      allergens, allergies, alcohol, wine, label, beverages, labeling, allergen, labels, ingredients                                                      I stand with the new proposal to require allergen labeling for wines, distilled spirits, and malt beverages. This regulation is essential to ensure that consumers are fully informed about the ingredients in the beverages they consume and to reduce the risk of allergic reactions due to misinformation. For individuals with allergies, drinking a beverage containing an allergen poses the same health r ||| Allergens are not typically used in the production of wine, mandatory allergen statements should only be used when legitimate contact is made during production with allergens. In following federal and state level compliance for the labelling of alcoholic beverages, members of the industry are now faced with seemingly needing to also label with regard to the FDA and there is not enough room on the  ||| As someone with a food allergy myself, I understand the risk and the struggles that accompany a food allergy.  Clear labeling is imperative to ensuring those with allergies like myself are informed of what we are ingesting and can act appropriately if we find we have congested or are about to congest something that we are allergic to.  Since alcohol, including wines, distilled spirits, and malt be ||| I support Notice No. 238: Major Food Allergen Labeling for Wines, Distilled Spirits, and Malt Beverages, with the foremust concern being the benefits it can have on consumer safety. Consuming an alcoholic beverage with an unlabeled allergen can be life-threatening, and the failure to implement this policy would lead to a dangerous gap in current food and beverage labling standards in the US. Witho ||| I write in favor of this regulation.<br/><br/>I think it is wise to require major food allergens to be included on labels for wines, spirits, and malt beverages. Many who suffer from such allergies may not realize that such allergens are used in the production of those beverages and requiring producers to include allergen information is prudent.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # load and filter\n",
    "    df = load_data(DATA_PATH)\n",
    "    df = filter_by_docket(df, DOCKET_TO_USE)\n",
    "    df = df.dropna(subset=[TEXT_COL]).reset_index(drop=True)\n",
    "    print(\"Docs in df:\", len(df))\n",
    "\n",
    "    # prepare docs and ids\n",
    "    documents = df[TEXT_COL].astype(str).tolist()\n",
    "    document_ids = df[DOC_ID_COL].astype(str).tolist()\n",
    "\n",
    "    # train\n",
    "    model = train_top2vec(\n",
    "        documents=documents,\n",
    "        document_ids=document_ids,\n",
    "        embedding_model=EMBEDDING_MODEL,\n",
    "        speed=SPEED,\n",
    "        workers=WORKERS\n",
    "    )\n",
    "\n",
    "    # outputs\n",
    "    n_topics = model.get_num_topics()\n",
    "    print(\"Number of topics discovered:\", n_topics)\n",
    "    topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "    print(\"Top 10 topic sizes (docs per topic):\")\n",
    "    for size, num in zip(topic_sizes[:10], topic_nums[:10]):\n",
    "        print(f\"  Topic {num}: {size} documents\")\n",
    "\n",
    "    # map topics back to df (dominant + topN)\n",
    "    df = map_dominant_and_topN(model, df, DOC_ID_COL, TEXT_COL, topN=3)\n",
    "\n",
    "    # label topics using top terms\n",
    "    topic_label_map = build_topic_label_map(model, top_k_words=TOP_N_FOR_LABEL)\n",
    "    df[\"top2vec_terms\"] = df[\"top2vec_dominant_topic\"].map(topic_label_map).fillna(\"Unclear\")\n",
    "\n",
    "    # topic summary table\n",
    "    topic_summary = build_topic_summary_df(model, df, TEXT_COL, top_words=TOP_WORDS_PER_TOPIC, sample_docs=SAMPLE_DOCS_PER_TOPIC)\n",
    "    topic_summary.to_csv(TOPIC_SUMMARY_CSV, index=False)\n",
    "    print(f\"Topic summary saved to {TOPIC_SUMMARY_CSV}\")\n",
    "\n",
    "    # save df with topic columns\n",
    "    df.to_csv(OUTPUT_DF_CSV, index=False)\n",
    "    print(f\"Comments with topic columns saved to {OUTPUT_DF_CSV}\")\n",
    "\n",
    "    # save model\n",
    "    model.save(str(MODEL_SAVE_FILE))\n",
    "    print(\"Model saved to:\", MODEL_SAVE_FILE)\n",
    "    # temporary until repo is finalized \n",
    "    # MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    # model.save(str(MODEL_SAVE_DIR))\n",
    "    # print(\"Model saved to:\", MODEL_SAVE_DIR)\n",
    "\n",
    "    # check\n",
    "    print(\"topic_summary (top rows):\")\n",
    "    print(topic_summary.head(10).to_string(index=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
