{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1517537a-fc32-49b7-9950-93860af4d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9265824-bd0e-4e46-a8a3-52b50d05186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ CONFIG ------------------\n",
    "# Try to detect repo root\n",
    "try:\n",
    "    REPO_ROOT = Path(__file__).parent.parent.resolve()\n",
    "except NameError:\n",
    "    REPO_ROOT = Path(os.getcwd()).parent.resolve()\n",
    "\n",
    "OUTPUTS_DIR = REPO_ROOT / \"outputs\"\n",
    "OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "COMMENTS_CSV = OUTPUTS_DIR / \"all_comments_with_bertopic_combined.csv\" \n",
    "TOPIC_SUMMARY_CSV = OUTPUTS_DIR / \"all_bertopic_topic_summary_combined.csv\"\n",
    "\n",
    "# TOPIC_SUMMARY_CSV = OUTPUTS_DIR / \"top2vec_topic_summary.csv\"\n",
    "# COMMENTS_CSV = OUTPUTS_DIR / \"comments_with_top2vec.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce15d15-aedc-4ea3-a4be-d3086300b51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\Users\\linna\\OneDrive\\Documents\\Python_Dev\\topic-modeling\\app\\test_app.py\n"
     ]
    }
   ],
   "source": [
    "# # ------------------ CREATE TEMP STREAMLIT SCRIPT ------------------\n",
    "APP_SCRIPT = REPO_ROOT / \"app/test_app.py\"\n",
    "APP_SCRIPT.parent.mkdir(exist_ok=True)  # ensure app folder exists\n",
    "\n",
    "app_template = r'''\n",
    "# -*- coding: utf-8 -*-\n",
    "from pathlib import Path\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from typing import Optional\n",
    "import streamlit.components.v1 as components\n",
    "\n",
    "# --- CONFIG: CSV paths injected by the notebook ---\n",
    "DEFAULT_TOPIC_SUMMARY = Path(r\"__TOPIC_SUMMARY__\")\n",
    "DEFAULT_COMMENTS_DF = Path(r\"__COMMENTS_CSV__\")\n",
    "\n",
    "# Basic page config\n",
    "st.set_page_config(page_title=\"Topic Explorer\", layout=\"wide\", initial_sidebar_state=\"expanded\")\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def load_csv_fallback(path: Path) -> Optional[pd.DataFrame]:\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    for enc in (\"utf-8\", \"cp1252\", \"latin-1\"):\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "topic_summary = load_csv_fallback(DEFAULT_TOPIC_SUMMARY)\n",
    "comments_df = load_csv_fallback(DEFAULT_COMMENTS_DF)\n",
    "\n",
    "if topic_summary is None or comments_df is None:\n",
    "    st.warning(\"Topic summary or comments CSV not found. Put the files in the expected paths and reload.\")\n",
    "    st.info(f\"Expected: topic_summary={DEFAULT_TOPIC_SUMMARY}, comments={DEFAULT_COMMENTS_DF}\")\n",
    "    st.stop()\n",
    "\n",
    "# convenience column names (prefer display columns if present)\n",
    "# 'display columns' are filtered after topics are generated to remove meaningless words -- LK has yet to build this in\n",
    "TOP_WORDS_COL = \"top_words_display\" if \"top_words_display\" in topic_summary.columns else \"top_words\"\n",
    "SAMPLE_COMMENTS_COL = \"sample_comments_display\" if \"sample_comments_display\" in topic_summary.columns else \"sample_comments\"\n",
    "TOPIC_NUM_COL = \"topic_num\" if \"topic_num\" in topic_summary.columns else (\"topic\" if \"topic\" in topic_summary.columns else None)\n",
    "if TOPIC_NUM_COL is not None:\n",
    "    topic_summary[TOPIC_NUM_COL] = topic_summary[TOPIC_NUM_COL].astype(int)\n",
    "\n",
    "# detect dominant-topic column in comments (make app amenable to top2vec or bert)\n",
    "DOM_COL_CANDIDATES = [\"bertopic_dominant_topic\", \"top2vec_dominant_topic\", \"dominant_topic\", \"topic\", \"topic_num\"]\n",
    "dom_col = next((c for c in DOM_COL_CANDIDATES if c in comments_df.columns), None)\n",
    "if dom_col is None:\n",
    "    dom_col = \"bertopic_dominant_topic\"\n",
    "    comments_df[dom_col] = -1\n",
    "comments_df[dom_col] = comments_df[dom_col].fillna(-1).astype(int)\n",
    "\n",
    "# optional emotion column\n",
    "EMOTION_COL = \"top_emotion\" if \"top_emotion\" in comments_df.columns else None\n",
    "\n",
    "# map topic labels; keep -1 as Noise\n",
    "topic_label_map = {}\n",
    "if TOPIC_NUM_COL is not None and TOP_WORDS_COL in topic_summary.columns:\n",
    "    topic_label_map = dict(zip(topic_summary[TOPIC_NUM_COL].astype(int), topic_summary[TOP_WORDS_COL].astype(str)))\n",
    "topic_label_map[-1] = \"Noise\"\n",
    "\n",
    "# --- Filtering and Display ---\n",
    "# 1) docket (top)\n",
    "docket_col = \"docket_id\" if \"docket_id\" in comments_df.columns else None\n",
    "if docket_col:\n",
    "    docket_choices = [\"(All)\"] + sorted(comments_df[docket_col].dropna().astype(str).unique().tolist())\n",
    "else:\n",
    "    docket_choices = [\"(All)\"]\n",
    "chosen_docket = st.sidebar.selectbox(\"Docket\", options=docket_choices, index=0)\n",
    "\n",
    "# 2) search comments (keyword)\n",
    "keyword = st.sidebar.text_input(\"Search comments (keyword)\", value=\"\")\n",
    "\n",
    "# Apply docket + search early to compute topic choices relevant to the query\n",
    "df_initial = comments_df.copy()\n",
    "if chosen_docket and chosen_docket != \"(All)\" and docket_col:\n",
    "    df_initial = df_initial[df_initial[docket_col].astype(str) == chosen_docket]\n",
    "if keyword:\n",
    "    kw = keyword.lower()\n",
    "    df_for_topics = df_initial[df_initial.apply(lambda r: kw in str(r.get(\"comment_text\",\"\")).lower() or kw in str(r.get(\"sample_comments\",\"\")).lower(), axis=1)]\n",
    "else:\n",
    "    df_for_topics = df_initial\n",
    "\n",
    "# 3) topics multi-select (choices come from docket+search filtered rows)\n",
    "all_topics = sorted(set(df_for_topics[dom_col].unique().tolist()))\n",
    "topic_choices = [\"All\"] + [str(t) for t in all_topics if t != -1] + ([\"Noise\"] if -1 in all_topics else [])\n",
    "selected_topics = st.sidebar.multiselect(\"Topics (multi-select)\", options=topic_choices, default=[\"All\"])\n",
    "\n",
    "# 4) emotion selector\n",
    "if EMOTION_COL:\n",
    "    emotion_choices = [\"All\"] + sorted(df_initial[EMOTION_COL].dropna().unique().tolist())\n",
    "    selected_emotion = st.sidebar.selectbox(\"Emotion\", emotion_choices, index=0)\n",
    "else:\n",
    "    selected_emotion = \"All\"\n",
    "\n",
    "# 5) min topic size slider\n",
    "min_topic_size_max = int(topic_summary[\"size\"].max()) if \"size\" in topic_summary.columns else 100\n",
    "min_topic_size = st.sidebar.slider(\"Min topic size (filter topic list)\", min_value=0, max_value=min_topic_size_max, value=0, step=1)\n",
    "\n",
    "# 6) show only 'noise' comments\n",
    "show_only_noise = st.sidebar.checkbox(\"Show only -1 (noise) docs\", value=False)\n",
    "\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.write(\"Display options\")\n",
    "show_sample_in_cards = st.sidebar.checkbox(\"Show sample text in topic cards\", value=True)\n",
    "cards_per_row = st.sidebar.selectbox(\"Cards per row\", options=[1,2,3,4], index=2)\n",
    "\n",
    "# --- Apply filters in the same order (start from docket-filtered df) ---\n",
    "filtered = comments_df.copy()\n",
    "if chosen_docket and chosen_docket != \"(All)\" and docket_col:\n",
    "    filtered = filtered[filtered[docket_col].astype(str) == chosen_docket]\n",
    "\n",
    "# keyword search\n",
    "if keyword:\n",
    "    kw = keyword.lower()\n",
    "    filtered = filtered[filtered.apply(lambda r: kw in str(r.get(\"comment_text\",\"\")).lower() or kw in str(r.get(\"sample_comments\",\"\")).lower(), axis=1)]\n",
    "\n",
    "# topic selection (honor \"Noise\" sentinel)\n",
    "if not (\"All\" in selected_topics or len(selected_topics) == 0):\n",
    "    sel = []\n",
    "    for t in selected_topics:\n",
    "        if str(t).lower() == \"noise\":\n",
    "            sel.append(-1)\n",
    "        else:\n",
    "            try:\n",
    "                sel.append(int(t))\n",
    "            except Exception:\n",
    "                pass\n",
    "    if sel:\n",
    "        filtered = filtered[filtered[dom_col].isin(sel)]\n",
    "\n",
    "# emotion filter\n",
    "if EMOTION_COL and selected_emotion != \"All\":\n",
    "    filtered = filtered[filtered[EMOTION_COL] == selected_emotion]\n",
    "\n",
    "# show only noise\n",
    "if show_only_noise:\n",
    "    filtered = filtered[filtered[dom_col] == -1]\n",
    "\n",
    "# compute large_topics set if min_topic_size used (based on global topic_summary)\n",
    "if \"size\" in topic_summary.columns and min_topic_size > 0:\n",
    "    large_topics = set(topic_summary[topic_summary[\"size\"].astype(int) >= min_topic_size][TOPIC_NUM_COL].astype(int).tolist())\n",
    "else:\n",
    "    large_topics = None\n",
    "\n",
    "# --- Update title and browser tab with chosen docket ---\n",
    "visible_title = f\"Topic Explorer — {chosen_docket}\" if chosen_docket and chosen_docket != \"(All)\" else \"Topic Explorer\"\n",
    "st.title(visible_title)\n",
    "components.html(f\"<script>document.title = \\\"{visible_title.replace('\\\"','\\\\\\\"')}\\\";</script>\", height=0)\n",
    "\n",
    "# --- summaries ---\n",
    "k1, k2, k3 = st.columns([1,1,2])\n",
    "k1.metric(\"Filtered comments\", f\"{len(filtered):,}\")\n",
    "k2.metric(\"Topics represented\", f\"{filtered[dom_col].nunique()}\")\n",
    "top_em = filtered[EMOTION_COL].value_counts().idxmax() if EMOTION_COL and not filtered[EMOTION_COL].empty else \"N/A\"\n",
    "k3.metric(\"Top emotion\", top_em)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# --- Charts: topic sizes and emotion distribution (responds to filtering) ---\n",
    "c1, c2 = st.columns([2,1])\n",
    "\n",
    "with c1:\n",
    "    st.subheader(\"Topic sizes\")\n",
    "    topic_counts = filtered[dom_col].value_counts().reset_index()\n",
    "    topic_counts.columns = [\"topic\",\"count\"]\n",
    "    topic_counts[\"label\"] = topic_counts[\"topic\"].map(lambda t: topic_label_map.get(int(t), f\"Topic {t}\"))\n",
    "    if not topic_counts.empty:\n",
    "        fig = px.bar(topic_counts.sort_values(\"count\"), x=\"count\", y=\"label\", orientation=\"h\", text=\"count\", height=420)\n",
    "        fig.update_layout(xaxis_title=\"Number of documents\", yaxis_title=\"Topic\", margin=dict(l=10,r=10,t=40,b=10))\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No topics to display (check filters).\")\n",
    "\n",
    "with c2:\n",
    "    st.subheader(\"Emotion distribution\")\n",
    "    if EMOTION_COL:\n",
    "        ec = filtered[EMOTION_COL].value_counts().reset_index()\n",
    "        ec.columns = [\"emotion\",\"count\"]\n",
    "        if not ec.empty:\n",
    "            fig2 = px.pie(ec, names=\"emotion\", values=\"count\")\n",
    "            fig2.update_traces(textposition='inside', textinfo='percent+label')\n",
    "            st.plotly_chart(fig2, use_container_width=True)\n",
    "        else:\n",
    "            st.info(\"No emotion data in filtered set.\")\n",
    "    else:\n",
    "        st.info(\"No emotion column available.\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# --- Display Mass Comment examples + counts\n",
    "\n",
    "# find mass comments:\n",
    "mass_col = \"comment_title\" if \"comment_title\" in comments_df.columns else None\n",
    "\n",
    "if mass_col:\n",
    "    import re\n",
    "\n",
    "    st.subheader(\"Mass Comment Example Text\")\n",
    "    # ensure display reacts to sidebar filters/search\n",
    "    mg = filtered.copy()\n",
    "    mg[mass_col] = mg[mass_col].fillna(\"\")\n",
    "\n",
    "    # get mass label (e.g., \"Mass Comment 1\") or None\n",
    "    def _extract_mass_label(val):\n",
    "        m = re.search(r\"(?i)\\b(Mass\\s*Comment\\s*\\d+)\\b\", str(val))\n",
    "        return m.group(1).strip() if m else None\n",
    "\n",
    "    mg[\"__mass_label\"] = mg[mass_col].apply(_extract_mass_label)\n",
    "\n",
    "    # keep only rows that are recognized as mass comments\n",
    "    mg = mg[mg[\"__mass_label\"].notna()].copy()\n",
    "\n",
    "    if mg.empty:\n",
    "        st.info(\"No mass comments found in the current filters.\")\n",
    "    else:\n",
    "        # group by mass label and docket\n",
    "        group_cols = [\"__mass_label\"]\n",
    "        if docket_col:\n",
    "            group_cols.append(docket_col)\n",
    "\n",
    "        # Prefer using mass_count (calculated in topic modeling step before deduplication).\n",
    "        if \"mass_count\" in mg.columns:\n",
    "            agg = (\n",
    "                mg.groupby(group_cols)\n",
    "                .agg(\n",
    "                    count=(\"mass_count\", \"max\"),  \n",
    "                    sample=(\"comment_text\", lambda s: next((x for x in s.dropna().tolist()), \"\")),\n",
    "                )\n",
    "                .reset_index()\n",
    "            )\n",
    "        else:\n",
    "            # fallback\n",
    "            count_col = \"comment_id\" if \"comment_id\" in mg.columns else mg.columns[0]\n",
    "            agg = (\n",
    "                mg.groupby(group_cols)\n",
    "                .agg(\n",
    "                    count=(count_col, \"count\"),\n",
    "                    sample=(\"comment_text\", lambda s: next((x for x in s.dropna().tolist()), \"\")),\n",
    "                )\n",
    "                .reset_index()\n",
    "            )\n",
    "\n",
    "        # iterate rows and display header: \"Mass Comment N (DOCKET_ID) — X comments\"\n",
    "        for idx, r in agg.iterrows():\n",
    "            label = str(r[\"__mass_label\"])\n",
    "            docket_val = str(r[docket_col]) if docket_col and pd.notna(r.get(docket_col)) else \"nodocket\"\n",
    "            cnt = int(r[\"count\"])\n",
    "            header = f\"{label} ({docket_val}) — {cnt} comments\"\n",
    "            st.markdown(f\"**{header}**\")\n",
    "\n",
    "            sample = str(r[\"sample\"])\n",
    "            if sample:\n",
    "                st.caption(sample[:500] + (\"...\" if len(sample) > 500 else \"\"))\n",
    "\n",
    "            # unique key using mass label + docket + index\n",
    "            safe_label = re.sub(r\"[^\\w\\-]+\", \"_\", label)\n",
    "            safe_docket = re.sub(r\"[^\\w\\-]+\", \"_\", docket_val)\n",
    "            btn_key = f\"mass_view_{safe_label}_{safe_docket}_{idx}\"\n",
    "\n",
    "            if st.button(f\"View {label} — all {cnt} comments\", key=btn_key):\n",
    "                # show all matching rows from the already-filtered mass-group dataframe\n",
    "                sub = mg[mg[\"__mass_label\"] == label].copy()\n",
    "                if docket_col and docket_val != \"nodocket\":\n",
    "                    sub = sub[sub[docket_col].astype(str) == docket_val]\n",
    "                display_cols = [\"comment_id\", \"comment_text\"] if \"comment_id\" in sub.columns else [\"comment_text\"]\n",
    "                if EMOTION_COL and EMOTION_COL in sub.columns:\n",
    "                    display_cols += [EMOTION_COL]\n",
    "                st.dataframe(sub[display_cols].head(2000), use_container_width=True)\n",
    "\n",
    "            st.markdown(\"\")  # spacer\n",
    "else:\n",
    "    st.info(\"No 'comment_title' column detected. To enable this panel, add a 'comment_title' column that contains values like 'Mass Comment 1' among other possible titles.\")\n",
    "\n",
    "# --- End Mass Comment Block (Dev) ---\n",
    "\n",
    "# --- Topic previews (show topic number + count in filtered set; green top-words subhead) ---\n",
    "st.subheader(\"Topic previews\")\n",
    "display_topics = topic_summary.copy()\n",
    "\n",
    "# restrict to topics that appear in the docket/search-filtered set\n",
    "topics_in_filtered = set(filtered[dom_col].unique().tolist())\n",
    "display_topics = display_topics[display_topics[TOPIC_NUM_COL].astype(int).isin(topics_in_filtered)]\n",
    "\n",
    "# apply user topic picks (if not \"All\")\n",
    "if not (\"All\" in selected_topics or len(selected_topics) == 0):\n",
    "    sel_topics = set()\n",
    "    for t in selected_topics:\n",
    "        if str(t).lower() == \"noise\":\n",
    "            sel_topics.add(-1)\n",
    "        else:\n",
    "            try:\n",
    "                sel_topics.add(int(t))\n",
    "            except Exception:\n",
    "                pass\n",
    "    display_topics = display_topics[display_topics[TOPIC_NUM_COL].astype(int).isin(sel_topics)]\n",
    "\n",
    "# apply min topic size (global) if requested\n",
    "if large_topics is not None:\n",
    "    display_topics = display_topics[display_topics[TOPIC_NUM_COL].astype(int).isin(large_topics)]\n",
    "\n",
    "# order and limit\n",
    "if \"size\" in display_topics.columns:\n",
    "    display_topics = display_topics.sort_values(\"size\", ascending=False)\n",
    "elif TOPIC_NUM_COL:\n",
    "    display_topics = display_topics.sort_values(TOPIC_NUM_COL)\n",
    "\n",
    "display_topics = display_topics.head(30).reset_index(drop=True)\n",
    "\n",
    "# prepare per-topic doc counts from the filtered set\n",
    "topic_counts_map = filtered[dom_col].value_counts().to_dict()\n",
    "\n",
    "if display_topics.empty:\n",
    "    st.info(\"No topic previews match filters.\")\n",
    "else:\n",
    "    cols = st.columns(cards_per_row)\n",
    "for i, row in display_topics.iterrows():\n",
    "    col = cols[i % cards_per_row]\n",
    "    with col:\n",
    "        tnum = int(row[TOPIC_NUM_COL]) if TOPIC_NUM_COL else i\n",
    "        # count from filtered set (reflects current filters)\n",
    "        cnt = int(topic_counts_map.get(tnum, 0))\n",
    "        header = f\"Topic {tnum} — {cnt} docs\"\n",
    "        # show header (topic number + count)\n",
    "        st.markdown(f\"### {header}\")\n",
    "        # green subhead with top words\n",
    "        top_words = row.get(TOP_WORDS_COL, row.get(\"top_words\", \"\"))\n",
    "        if top_words:\n",
    "            st.markdown(f\"<div style='color:green;margin-bottom:6px'>{top_words}</div>\", unsafe_allow_html=True)\n",
    "        if show_sample_in_cards:\n",
    "            sample = row.get(SAMPLE_COMMENTS_COL, row.get(\"sample_comments\", \"\"))\n",
    "            if sample:\n",
    "                st.caption(sample[:300] + (\"...\" if len(sample) > 300 else \"\"))\n",
    "\n",
    "        # prepare a unique key using tnum + docket_id + loop index\n",
    "        docket_id_val = row.get(\"docket_id\", \"nodocket\")\n",
    "        safe_docket = str(docket_id_val).replace(\" \", \"_\")\n",
    "        btn_key = f\"view_{tnum}_{safe_docket}_{i}\"\n",
    "\n",
    "        if st.button(f\"View comments (topic {tnum})\", key=btn_key):\n",
    "            sub = filtered[filtered[dom_col] == tnum]\n",
    "            # further filter by docket if available\n",
    "            if docket_col and docket_id_val != \"nodocket\":\n",
    "                sub = sub[sub[docket_col] == docket_id_val]\n",
    "            if sub.empty:\n",
    "                st.info(\"No comments for this topic (in current filters).\")\n",
    "            else:\n",
    "                st.write(f\"Showing {len(sub)} comments for topic {tnum} in docket {docket_id_val}\")\n",
    "                display_cols = [\"comment_id\",\"comment_text\"]\n",
    "                if EMOTION_COL:\n",
    "                    display_cols += [EMOTION_COL]\n",
    "                st.dataframe(sub[display_cols].head(200), use_container_width=True)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# --- View/download comments ---\n",
    "st.subheader(\"Browse filtered comments\")\n",
    "preview_cols = [\"comment_id\",\"comment_text\", dom_col]\n",
    "if EMOTION_COL:\n",
    "    preview_cols += [EMOTION_COL, \"top_emotion_score\"] if \"top_emotion_score\" in comments_df.columns else [EMOTION_COL]\n",
    "available_cols = [c for c in preview_cols if c in filtered.columns]\n",
    "st.dataframe(filtered[available_cols].head(500), height=400)\n",
    "\n",
    "csv_bytes = filtered.to_csv(index=False).encode(\"utf-8\")\n",
    "st.download_button(\"Download filtered comments\", csv_bytes, file_name=\"filtered_comments.csv\", mime=\"text/csv\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Use the controls on the left to filter docket, topics, emotions, and to search comments. Click topic cards to view related comments.\")\n",
    "'''\n",
    "\n",
    "\n",
    "app_code = app_template.replace(\"__TOPIC_SUMMARY__\", str(TOPIC_SUMMARY_CSV)).replace(\"__COMMENTS_CSV__\", str(COMMENTS_CSV))\n",
    "\n",
    "# write file\n",
    "APP_SCRIPT.write_text(app_code, encoding=\"utf-8\")\n",
    "print(\"Wrote:\", APP_SCRIPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aab786-372c-4ec9-abf0-6c781862ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ RUN STREAMLIT ------------------\n",
    "# This will open the app in your default browser\n",
    "subprocess.run([\"streamlit\", \"run\", str(APP_SCRIPT)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
